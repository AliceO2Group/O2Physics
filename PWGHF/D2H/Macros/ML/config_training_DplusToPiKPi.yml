---
channel: DplusToPiKPi
seed_split: 42 # seed used for df_bkg sampling and train_test_split(...)
labels: [Bkg, Prompt, Nonprompt] # class labels, keep the right number of classes

data_prep:
  indirs: # directories containing outputs of prepare_samples.py (.root labeled files)
    Prompt:
      [
        dirPath/
      ]
    Nonprompt: # set to null to deactivate this class
      [
        dirPath/
      ]
    Bkg:
      [
        dirPath/
      ]

  tree_name: treeMLDplus # null if .parquet input files, not null if .root input files

  pt_bins_limits: [1, 24]
  name_pt_var: fPt # name of pT branch in original TTree
  downsample_bkg_factor: 1 # value of downSampleBkgFactor set at TTree creation level

  class_balance:
    share: equal # change how the dataset is built, options available: 'equal', 'all_signal'
    # 'equal' -> same number of prompt/nonprompt/bkg (not using all the signal available)
    # 'all_signal' -> try to use all the signal (prompt and nonprompt) + add n_bkg = bkg_factor * (n_prompt + n_nonprompt)
    bkg_factor: [1.] # list of multipliers for (n_prompt + n_nonprompt) used to determine n_cand_bkg in the 'all_signal' option
  test_fraction: 0.3

ml:
  raw_output: false
  roc_auc_approach: ovo
  roc_auc_average: macro
  training_vars:
    [
      fPtProng0,
      fImpactParameter0,
      fPtProng1,
      fImpactParameter1,
      fPtProng2,
      fImpactParameter2,
      fDecayLength,
      fCpa,
      fCpaXY,
      fNSigTpcTofPi0,
      fNSigTpcTofKa0,
      fNSigTpcTofPi1,
      fNSigTpcTofKa1,
      fNSigTpcTofPi2,
      fNSigTpcTofKa2,
    ]
  hyper_pars: [
    {
      "max_depth": 3,
      "learning_rate": 0.045,
      "n_estimators": 800,
      "min_child_weight": 4,
      "n_jobs": 4,
      "tree_method": hist,
    }]
  hyper_pars_opt:
    activate: false
    ntrials: 25
    njobs: 4
    timeout: 1800
    hyper_par_ranges:
      {
        "max_depth": !!python/tuple [2, 3],
        "learning_rate": !!python/tuple [0.03, 0.06],
        "n_estimators": !!python/tuple [400, 2000],
        "min_child_weight": !!python/tuple [4, 4],
        "subsample": !!python/tuple [1, 1],
        "colsample_bytree": !!python/tuple [1, 1]
      }

output:
  dir: trainings/Dplus
  log_file: log.txt # name of log file for each model training
  # list of variables saved in the dataframes with the applied models
  column_to_save_list: ["fPt", "fM"]

plots:
  extra_columns: ["fPt", "fM"] # list of variables to plot (on top of the training ones)
  extension: ["pdf", "png"] # extension of files containing saved plots
